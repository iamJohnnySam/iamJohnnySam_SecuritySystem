{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamJohnnySam/iamJohnnySam_SecuritySystem/blob/main/CCTV_Image_Classifier_2023_10_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "zuOIbHUks8gd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FPm5P0njzM_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ef24ad-6c73-4ec9-cf1b-5ce74a2c170b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x35GsO1IVDUs"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cqKjVHmK1MUc"
      },
      "outputs": [],
      "source": [
        "rootLoc1 = '/content/drive/My Drive/Personal Projects/CCTV/A01/'\n",
        "rootLoc2 = '/content/drive/My Drive/Personal Projects/CCTV/A02/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Images"
      ],
      "metadata": {
        "id": "2IcaU8tLs_69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil"
      ],
      "metadata": {
        "id": "pOtzdO8Dt2BN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_photos_sub (dir, folder, cat, tr, va, te):\n",
        "    train_folder = folder + \"/train/\" + cat\n",
        "    test_folder = folder + \"/test/predict\"\n",
        "    val_folder = folder + \"/validation/\" + cat\n",
        "\n",
        "    for folder_path in [train_folder, val_folder, test_folder]:\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    random.seed(42)\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "    imgs_list = [filename for filename in os.listdir(dir) if os.path.splitext(filename)[-1] in image_extensions]\n",
        "\n",
        "    random.shuffle(imgs_list)\n",
        "\n",
        "    print(len(imgs_list))\n",
        "    train_size = int(len(imgs_list) * tr)\n",
        "    val_size = int(len(imgs_list) * va)\n",
        "    test_size = int(len(imgs_list) * te)\n",
        "\n",
        "    for i, f in enumerate(imgs_list):\n",
        "        if i < train_size:\n",
        "            dest_folder = train_folder\n",
        "        elif i < train_size + val_size:\n",
        "            dest_folder = val_folder\n",
        "        else:\n",
        "            dest_folder = test_folder\n",
        "\n",
        "        shutil.copy(os.path.join(dir, f), os.path.join(dest_folder, f))\n",
        "\n",
        "\n",
        "def split_photos (dir, folder, tr, va, te):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "        os.makedirs(folder + \"/train\")\n",
        "        os.makedirs(folder + \"/test\")\n",
        "        os.makedirs(folder + \"/validation\")\n",
        "\n",
        "    split_photos_sub (dir + \"0\", folder, \"0\", tr, va, te)\n",
        "    split_photos_sub (dir + \"1\", folder, \"1\", tr, va, te)"
      ],
      "metadata": {
        "id": "MEr32XlktDdp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier\n"
      ],
      "metadata": {
        "id": "3GHwB7XO0FHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def classify (loc):\n",
        "    datagen = ImageDataGenerator()\n",
        "\n",
        "    train_it = datagen.flow_from_directory(loc + '/train/',\n",
        "                                           class_mode='binary',\n",
        "                                           target_size = (288, 352),\n",
        "                                           batch_size=64)\n",
        "    val_it = datagen.flow_from_directory(loc + '/validation/',\n",
        "                                         class_mode='binary',\n",
        "                                         target_size = (288, 352),\n",
        "                                         batch_size=64)\n",
        "    test_it = datagen.flow_from_directory(loc + '/test/',\n",
        "                                          class_mode='binary',\n",
        "                                          target_size = (288, 352),\n",
        "                                          batch_size=64)\n",
        "\n",
        "\n",
        "    return (train_it, val_it, test_it)"
      ],
      "metadata": {
        "id": "6jrdxY6z0Sm1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9SBdWgzxn-C"
      },
      "source": [
        "# Graph Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GrmtR3Hqxqsb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plotNNGraph (history):\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert"
      ],
      "metadata": {
        "id": "YgfEjtKK9-Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "vijOuNZl-pKy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_model (model, cat):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    # Save the model.\n",
        "    with open('/content/drive/My Drive/Personal Projects/CCTV/model' + cat + '.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)"
      ],
      "metadata": {
        "id": "XOv7I0Mh-qCJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Camera Channel A01"
      ],
      "metadata": {
        "id": "_pBzGDfWzqxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_photos (rootLoc1, \"A01\", 0.7, 0.2, 0.1)\n",
        "train, val, test = classify (\"A01\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSW_oNlZVX67",
        "outputId": "c410a683-99c2-4e20-f957-c550d1c9467d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1681\n",
            "1676\n",
            "Found 2349 images belonging to 2 classes.\n",
            "Found 671 images belonging to 2 classes.\n",
            "Found 337 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Conv1D(64, (3),\n",
        "               activation='relu',\n",
        "               padding='same',\n",
        "               kernel_initializer='random_normal',\n",
        "               input_shape=(288, 352, 3)))\n",
        "\n",
        "cnn.add(MaxPooling2D(pool_size = (2)))\n",
        "cnn.add(Dropout(0.2))\n",
        "cnn.add(Conv1D(64, kernel_size = (3), activation = 'relu',\n",
        "               kernel_initializer='random_normal'))\n",
        "cnn.add(MaxPooling2D(pool_size = (2)))\n",
        "cnn.add(Conv1D(64, kernel_size = (3), activation = 'relu',\n",
        "               kernel_initializer='random_normal'))\n",
        "cnn.add(MaxPooling2D(pool_size = (2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(64, activation='relu'))\n",
        "cnn.add(Dense(32, activation='relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "cnn.add(Dense(8, activation='relu'))\n",
        "cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "cnn.compile(loss=\"binary_crossentropy\",\n",
        "            optimizer=\"adam\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "history = cnn.fit(train,\n",
        "                validation_data = val,\n",
        "                steps_per_epoch = train.n//train.batch_size,\n",
        "                validation_steps = val.n//val.batch_size,\n",
        "                epochs=5)\n",
        "\n",
        "plotNNGraph(history)\n",
        "convert_model (cnn, \"A01\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXJPctL1_4Oy",
        "outputId": "c34e2332-e205-4b43-e212-1b6636fba402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "36/36 [==============================] - 777s 22s/step - loss: 4.4029 - accuracy: 0.6376 - val_loss: 0.5321 - val_accuracy: 0.8547\n",
            "Epoch 2/5\n",
            "36/36 [==============================] - 771s 21s/step - loss: 0.5637 - accuracy: 0.8162 - val_loss: 0.5325 - val_accuracy: 0.8484\n",
            "Epoch 3/5\n",
            "19/36 [==============>...............] - ETA: 5:16 - loss: 0.5079 - accuracy: 0.8354"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Camera Channel A02"
      ],
      "metadata": {
        "id": "gjQHyoOHWxoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_photos (rootLoc1, \"A02\", 0.7, 0.2, 0.1)\n",
        "train, val, test = classify (\"A02\")"
      ],
      "metadata": {
        "id": "270_WKRGWXub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Conv1D(64, (3),\n",
        "               activation='relu',\n",
        "               padding='same',\n",
        "               kernel_initializer='random_normal',\n",
        "               input_shape=(288, 352, 3)))\n",
        "\n",
        "cnn.add(MaxPooling2D(pool_size = (2)))\n",
        "cnn.add(Dropout(0.2))\n",
        "cnn.add(Conv1D(64, kernel_size = (3), activation = 'relu',\n",
        "               kernel_initializer='random_normal'))\n",
        "cnn.add(MaxPooling2D(pool_size = (2)))\n",
        "cnn.add(Conv1D(64, kernel_size = (3), activation = 'relu',\n",
        "               kernel_initializer='random_normal'))\n",
        "cnn.add(MaxPooling2D(pool_size = (2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(64, activation='relu'))\n",
        "cnn.add(Dense(32, activation='relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "cnn.add(Dense(8, activation='relu'))\n",
        "cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "cnn.compile(loss=\"binary_crossentropy\",\n",
        "            optimizer=\"adam\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "history = cnn.fit(train,\n",
        "                validation_data = val,\n",
        "                steps_per_epoch = train.n//train.batch_size,\n",
        "                validation_steps = val.n//val.batch_size,\n",
        "                epochs=5)\n",
        "\n",
        "plotNNGraph(history)\n",
        "convert_model (cnn, \"A02\")"
      ],
      "metadata": {
        "id": "UURGV41nWMRS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7AVxm/veizq4t77zOfcPF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}